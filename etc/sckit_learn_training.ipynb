{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 01 : Setting (import Library)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02 : NumPy API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 개요 : 머신러닝의 근본 / 행렬 배열 계산\n",
    "- 차원\n",
    "    - [ ] = axis 중첩수 : 차원수\n",
    "    - axis0 : 신규차원의 방향이 axis0  \n",
    "- 생성\n",
    "    - import numpy as np\n",
    "    - np.array( [ndarray] )\n",
    "    - np.arange( start = int , stop = int )\n",
    "    - np.zeros( int, int)\n",
    "    - np.ones( int, int)\n",
    "- 재구성\n",
    "    - A.reshape( axis0 size , axis1 size , axis2 size ... )\n",
    "        - -1 을 넣는 다면 타 입력값에 맞춰 적절한 값을 자동으로 적용해 준다\n",
    "- 인덱싱\n",
    "    - Sampling : array[ int , int ]\n",
    "    - Slicing : array[ 1:3 , : ]\n",
    "    - Fancy index : array[ [1,2,3], 1:3 ]\n",
    "        - 연속된 값의 경우 차원이 축소 되지 않는다\n",
    "    - Boolean index : array_answer = array[ array > 5 ]\n",
    "- 정렬\n",
    "    - np.sort( [ndarray] )\n",
    "        - 원 행렬은 유지한 채 재정렬된 행렬을 반환\n",
    "    - ndarray.sort()\n",
    "        - 원 행렬 자체를 지정한 형태로 재정렬 후 , 반환값은 None\n",
    "        - default : 오름차순 , 내림차순 ndarray.sort()[::-1]\n",
    "    - np.argsort( )\n",
    "- 선형대수 연산\n",
    "    - 내적 : np.dot( A , B)\n",
    "    - 전치 : np.transpose( A )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 03 : Pandas API  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 개요 : Python 데이터 처리에 있어 가장 인기있는 라이브러리\n",
    "- 구성\n",
    "    - Series : Index / DataFrame : Index & Column\n",
    "- 생성\n",
    "    - import pandas as pd\n",
    "    - pd.read_csv('파일명.csv')\n",
    "    - pd.DataFrame(dic_name)\n",
    "- DATA check\n",
    "    - A.head()\n",
    "    - A.tail()\n",
    "    - A.info()\n",
    "    - A.shape()\n",
    "    - A.describe()\n",
    "    - df_name['col_name'].value_count()\n",
    "        - dropna = True : default\n",
    "        - dropna = False : null 값도 count 를 진행한다\n",
    "- Type change\n",
    "    - List -> ndarray -> DF\n",
    "    - dict -> DF\n",
    "    - DF -> ndarray -> List\n",
    "    - DF -> dict\n",
    "- axis 추가\n",
    "    - A['new_col'] = data or A['col'] func\n",
    "- axis 수정\n",
    "    - A['org_col'] = data or A['col'] func\n",
    "- axis 삭제 : 지정axis ( col or row ) 삭제\n",
    "    - A.drop(['name_1', 'name_2',...], axis = , inplace = ]\n",
    "        - inplace = Flase (default)\n",
    "        - inplace = True\n",
    "- axis 재정렬\n",
    "    - A.reset_index([drop = , inplace = )\n",
    "- axis 재명명\n",
    "    - A.rename(columns = {'old_1' : 'new_1' , 'old_2' : 'new_2'}, inplace = ) \n",
    "- 필터링\n",
    "    - 기본식 : A['col_name']\n",
    "    - 명칭기반\n",
    "        - A['col'].loc[ , ]\n",
    "    - 위치기반\n",
    "        - A['col'].iloc[ , ]\n",
    "    - Boolean indexing\n",
    "        - A[ boolean ]\n",
    "- 정렬\n",
    "    - A.sort_values(by = 'col_name' , asending = , inplace = )\n",
    "- Aggregation (집합연산)\n",
    "    - .sum()\n",
    "    - .max()\n",
    "    - .min()\n",
    "    - .count()\n",
    "    - .mean()\n",
    "- GroupBy\n",
    "    - A.groupby(by='col_name').agg({ 'col_1' : [np.func_1, np.func_2], 'col_2' : np.func_3 })\n",
    "- Null data\n",
    "    - null check\n",
    "        - A['col'].isna()\n",
    "    - null fill\n",
    "        - A['col'].fillna('a')\n",
    "        - A['col'].replace(np.nan, 'new_data', inplace = )\n",
    "- 고유값 확인\n",
    "    - A['col'].value_counts() : 객체 고유값의 수량\n",
    "    - A['col'].nunique() : 객체 고유값의 종류 가짓 수\n",
    "- DF 변경\n",
    "    - A['col'].replace( { 'org_data' : 'new_data' }, inplace = )\n",
    "    - A['col'].replace(np.nan, 'new_data', inplace = )\n",
    "- lambda\n",
    "    - func = lambda x : return_value\n",
    "    - .apply(lambda x : return)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 : Setting (Import Libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 data EDA Library\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import random as rnd \n",
    "import missingno as msno\n",
    "import sklearn\n",
    "import xgboost\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 plot vizualize Library\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "import seaborn as sns \n",
    "sns.set(font_scale=1.0) \n",
    "plt.style.use('seaborn-whitegrid') \n",
    "sns.set_theme(style='whitegrid', font_scale=1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 ML / DL Library\n",
    "import tensorflow as tf\n",
    "import keras as kr \n",
    "from keras import layers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 scikit-learn algorithm\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier, BaggingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC    \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 모델 튜닝 및 평가\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import model_selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 경고 제거 (판다스가 에어 메섹지를 자주 만들어 내기 때문)\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 : Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00 - Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "print(iris.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 - ndarray_data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'iris.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 - DF_data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 - 임의 분할 : train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train_test_split() :  0.9556\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state = 5)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size = 0.3 , random_state = 5)\n",
    "\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "pred = dt_clf.predict(X_test)\n",
    "\n",
    "accuracy_tts = accuracy_score(pred, y_test)\n",
    "\n",
    "print('# train_test_split() : ', np.round(accuracy_tts,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 - Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Kfold 1 차 결과 : 0.0000\n",
      "# Kfold 2 차 결과 : 0.0000\n",
      "# Kfold 3 차 결과 : 0.0000\n",
      "# 1~3 차 Kfold 교차검증 평균 : 0.0000\n"
     ]
    }
   ],
   "source": [
    "df_clf = DecisionTreeClassifier(random_state = 5)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits = 3)\n",
    "\n",
    "accuracy_kfold = []\n",
    "n = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(iris.data) : # 설정된 n_split 만큼 분할되어 index 를 반환\n",
    "    n = n + 1\n",
    "    X_train, X_test = iris.data[train_index], iris.data[test_index]\n",
    "    y_train, y_test = iris.target[train_index], iris.target[test_index]\n",
    "\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(pred, y_test)\n",
    "    print('# Kfold {} 차 결과 : {:.4f}'.format(n, np.round(accuracy,4)))\n",
    "\n",
    "    accuracy_kfold.append(accuracy)\n",
    "\n",
    "print('# 1~{} 차 Kfold 교차검증 평균 : {:.4f}'.format(n, np.round(np.mean(accuracy_kfold),4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05 - Stratified Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# stf_Kfold 1 차 결과 : 0.9800\n",
      "# stf_Kfold 2 차 결과 : 0.9400\n",
      "# stf_Kfold 3 차 결과 : 0.9800\n",
      "# 1~3 차 Kfold 교차검증 평균 : 0.9667\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state = 5)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "stf_kfold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "accuracy_stf_kfold = []\n",
    "n = 0\n",
    "\n",
    "for train_index, test_index in stf_kfold.split(iris.data, iris.target) :\n",
    "    n = n + 1    \n",
    "    X_train, X_test = iris.data[train_index], iris.data[test_index]\n",
    "    y_train, y_test = iris.target[train_index], iris.target[test_index]\n",
    "\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(pred, y_test)\n",
    "    print('# stf_Kfold {} 차 결과 : {:.4f}'.format(n, np.round(accuracy,4)))\n",
    "\n",
    "    accuracy_stf_kfold.append(accuracy)\n",
    "\n",
    "print('# 1~{} 차 Kfold 교차검증 평균 : {:.4f}'.format(n, np.round(np.mean(accuracy_stf_kfold),4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06 - cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도 :  [0.98 0.94 0.98]\n",
      "평균 교차검증 정확도 :  0.9667\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state = 5)\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict, cross_validate\n",
    "accuracy_cvs = cross_val_score(dt_clf, iris.data, iris.target, scoring = 'accuracy', cv = 3)\n",
    "\n",
    "print('교차 검증별 정확도 : ', np.round(accuracy_cvs,4))\n",
    "print('평균 교차검증 정확도 : ', np.round(np.mean(accuracy_cvs),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07 - GridSearch CV\n",
    "교차검증과 최적 하이퍼 파라미터 튜닝을 한번에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>5</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>5</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.676190                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.676190                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.961905                1   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.961905                1   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.961905                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.961905                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0           0.657143           0.685714           0.685714  \n",
       "1           0.657143           0.685714           0.685714  \n",
       "2           0.971429           0.971429           0.942857  \n",
       "3           0.971429           0.971429           0.942857  \n",
       "4           0.971429           0.971429           0.942857  \n",
       "5           0.971429           0.971429           0.942857  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSerachCV 최적 parameter :  {'max_depth': 2, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도 : 0.9619\n",
      "# 테스트 데이터 정확도 : 0.9333\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size = 0.3, random_state = 5)\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# 파라미터 설정 : Dict\n",
    "parameter = { 'max_depth' : [1,2,3], 'min_samples_split' : [2,3] }\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# GridSearchCV 설정 \n",
    "    # param_grid의 하이퍼 파라미터를 3개의(cv = 3) train, test set fold 로 나누어 테스트 수행 설정\n",
    "        # (max_dapth) * (min_sample_split) * (cv) = 3 * 2 * 2 = 18 set\n",
    "grid_dtree = GridSearchCV(dtree, param_grid = parameter, cv = 3, refit = True)\n",
    "\n",
    "# 학습/검증\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "# GridSearchCV 결과 dType 변환\n",
    "    # Dict -> DataFrame\n",
    "score_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "display(score_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score']])\n",
    "\n",
    "# GridSearchCV 결과 분석\n",
    "print('GridSerachCV 최적 parameter : ', grid_dtree.best_params_)\n",
    "print('GridSearchCV 최고 정확도 : {:.4f}'.format(grid_dtree.best_score_))\n",
    "\n",
    "# GridSearchCV 의 refit에 의해 학습된 estimator 반환\n",
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "# test 데이터 평가\n",
    "    # GridSearchCV 의 .best_estimator 는 이미 최적 학습이 완료 되었으므로 별도 추가 학습이 필요없음\n",
    "pred = estimator.predict(X_test)\n",
    "accuracy_grd = accuracy_score(pred, y_test)\n",
    "print('# 테스트 데이터 정확도 : {:.4f}'.format(accuracy_grd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08 - 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train_test_split 정확도 :  0.9556\n",
      "\n",
      "# Kfold 교차검증 별 정확도 :  [0. 0. 0.]\n",
      "## Kfold 교차검증 평균 정확도 :  0.0\n",
      "\n",
      "# Stratified Kfold 교차검증 별 정확도 :  [0.98 0.94 0.98]\n",
      "## Stratified Kfold 교차검증 평균 정확도 :  0.9667\n",
      "\n",
      "# cross_val_scroe 교차검증 별 정확도 :  [0.98 0.94 0.98]\n",
      "## cross_val_score 교차검증 평균 정확도 :  0.9667\n",
      "\n",
      "# GridSearchCV 최적 튜닝 시 각 정확도 :  [0.6762 0.6762 0.9619 0.9619 0.9619 0.9619]\n",
      "# GridSearchCV 최적 튜닝 시 최대 정확도 :  0.9619\n",
      "## GridSearchCV 하이퍼튜닝 최종 교차검증 정확도 :  0.9333\n"
     ]
    }
   ],
   "source": [
    "print('# train_test_split 정확도 : ', np.round(accuracy_tts,4))\n",
    "print('')\n",
    "\n",
    "print('# Kfold 교차검증 별 정확도 : ', np.round(accuracy_kfold,4))\n",
    "print('## Kfold 교차검증 평균 정확도 : ', np.round(np.mean(accuracy_kfold),4))\n",
    "print('')\n",
    "\n",
    "print('# Stratified Kfold 교차검증 별 정확도 : ', np.round(accuracy_stf_kfold,4))\n",
    "print('## Stratified Kfold 교차검증 평균 정확도 : ', np.round(np.mean(accuracy_stf_kfold),4))\n",
    "print('')\n",
    "\n",
    "print('# cross_val_scroe 교차검증 별 정확도 : ', np.round(accuracy_cvs,4))\n",
    "print('## cross_val_score 교차검증 평균 정확도 : ', np.round(np.mean(accuracy_cvs),4))\n",
    "print('')\n",
    "\n",
    "print('# GridSearchCV 최적 튜닝 시 각 정확도 : ', np.round(score_df['mean_test_score'].tolist(),4))\n",
    "print('# GridSearchCV 최적 튜닝 시 최대 정확도 : ', np.round(np.max(score_df['mean_test_score']),4))\n",
    "print('## GridSearchCV 하이퍼튜닝 최종 교차검증 정확도 : ', np.round(np.mean(accuracy_grd),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bdc2b39dba4a1a2bb6d840bc8828727e3a4c4135026ee5b84640756028bbf810"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
